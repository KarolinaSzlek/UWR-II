{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 132,
   "metadata": {},
   "outputs": [],
   "source": [
    "# setup\n",
    "import urllib\n",
    "from bs4 import BeautifulSoup\n",
    "from bs4.element import Comment\n",
    "import re\n",
    "\n",
    "from collections import defaultdict, deque\n",
    "\n",
    "import concurrent"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Zadanie 3.\n",
    "Napisz własny system do indeksowania stron internetowych, który\n",
    "\n",
    "• przegląda strony i zapamiętuje liczbę wystąpień poszczególnych słów na poszczególnych stronach;\n",
    "\n",
    "• zachowuje się podobnie jak pythonowy słownik, gdzie kluczem jest słowo, a wartością lista stron na których to słowo występuje (bądź lista pusta). Strony powinny być uszeregowane malejąco względem podanej liczby wystąpień. Możesz też zaproponować własną strategię rankowania stron.\n",
    "\n",
    "Zakładamy, że indeksujemy tylko stronę wskazaną jako parametr odpowiedniej funkcji czy metody, oraz strony do których da się dojść po linkach a href w nie więcej niż z góry zadana liczba kroków."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 166,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load(url):\n",
    "    \n",
    "    try:\n",
    "        urllib.request.urlopen(url)\n",
    "    except urllib.request.HTTPError as e:\n",
    "        print('Ignored: ', e)\n",
    "        return -1\n",
    "    except urllib.request.URLError as e:\n",
    "        print('URLError: ', e)\n",
    "        return -1\n",
    "    except Exception as e:\n",
    "        print('Error: ', e)\n",
    "        return -1\n",
    "    \n",
    "    page = urllib.request.urlopen(url).read()\n",
    "    data = BeautifulSoup(page, \"html.parser\")\n",
    "    return data\n",
    "\n",
    "\n",
    "def find_hrefs(url):\n",
    "    content = load(url)\n",
    "    if content == -1:\n",
    "        return []\n",
    "    ahrefs = content.findAll('a', href=True)\n",
    "    \n",
    "    res = []\n",
    "    for a in ahrefs:\n",
    "        link = a['href']\n",
    "        \n",
    "        if link is None or len(link) == 0:\n",
    "            continue\n",
    "        if re.search('^http', link) is not None:\n",
    "            res.append(link)\n",
    "        else:\n",
    "            if link[0] != '/':\n",
    "                res.append(url + link)\n",
    "            else:\n",
    "                link_start = link.split('/')[1]\n",
    "                find = re.search('/'+link_start+'/', url)\n",
    "                if find is not None:\n",
    "#                     print(link_start, link, url, find.start(), url[:find.start()])\n",
    "                    res.append(url[:find.start()] + link)\n",
    "                else:\n",
    "                    res.append(url + link)\n",
    "    return res\n",
    "\n",
    "\n",
    "def count_words(url):\n",
    "    '''\n",
    "    returns dictionary of - word: (url, #occurances)\n",
    "    '''\n",
    "    def find_words(url):\n",
    "        def text_from_html(url):\n",
    "            def tag_visible(element):\n",
    "                return not element.parent.name in ['style', 'script', 'head', 'title', 'meta', '[document]'] and not isinstance(element, Comment)\n",
    "\n",
    "            content = load(url)\n",
    "            if content == -1:\n",
    "                return \"\"\n",
    "            texts = content.findAll(text=True)\n",
    "            visible_texts = filter(tag_visible, texts)\n",
    "            return u\" \".join(t.strip() for t in visible_texts)\n",
    "        \n",
    "        text = text_from_html(url)\n",
    "        text = [re.sub('\\W+', '', t) for t in text.lower().split()]\n",
    "        return list(filter(len, text))\n",
    "    \n",
    "    words = find_words(url)\n",
    "    word_counts = defaultdict(int)\n",
    "    for w in words:\n",
    "        word_counts[w] += 1\n",
    "        \n",
    "    res = defaultdict(list)\n",
    "    for word, occurances in word_counts.items():\n",
    "        res[word] = (url, occurances)\n",
    "    return res\n",
    "\n",
    "\n",
    "def sort_dict(d):\n",
    "    return dict(sorted(d.items(), key=lambda kv: kv[1], reverse=True))\n",
    "\n",
    "\n",
    "def BFS(url, steps, max_steps):\n",
    "    '''\n",
    "    returns dict - word: list of (website, #occurances)\n",
    "    '''\n",
    "    q = deque()\n",
    "    q.append((url, steps))\n",
    "    visited = {url}\n",
    "    website_word_counts = defaultdict(list)\n",
    "    \n",
    "    while(len(q)):\n",
    "        url, steps = q.popleft()\n",
    "        if steps > max_steps:\n",
    "            break\n",
    "        \n",
    "        print(f'depth: {steps} / {max_steps}\\t:\\t{url}')\n",
    "        for word, wb_occ in count_words(url).items():\n",
    "            website_word_counts[word].append(wb_occ)\n",
    "            \n",
    "        for h in find_hrefs(url):\n",
    "            if h not in visited:\n",
    "                visited.add(h)\n",
    "                q.append((h, steps+1))\n",
    "    \n",
    "    # sort websites by no of appereances for every word\n",
    "    for k, v in website_word_counts.items():\n",
    "        website_word_counts[k] = list(sorted(website_word_counts[k], key=lambda kv: kv[1], reverse=True))\n",
    "    return website_word_counts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 167,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "depth: 0 / 1\t:\thttps://en.wikipedia.org/wiki/Alpman\n",
      "depth: 1 / 1\t:\thttps://en.wikipedia.org/wiki/Alpman#mw-head\n",
      "depth: 1 / 1\t:\thttps://en.wikipedia.org/wiki/Alpman#p-search\n",
      "depth: 1 / 1\t:\thttps://en.wiktionary.org/wiki/Alpman\n",
      "depth: 1 / 1\t:\thttps://en.wikipedia.org/wiki/Ayten_Alpman\n",
      "depth: 1 / 1\t:\thttps://en.wikipedia.org/wiki/Fatma_Serpil_Alpman\n",
      "depth: 1 / 1\t:\thttps://en.wikipedia.org/wiki/Surname\n",
      "depth: 1 / 1\t:\thttps://en.wikipedia.org/w/index.php?title=Special:WhatLinksHere/Alpman&namespace=0\n",
      "depth: 1 / 1\t:\thttps://en.wikipedia.org/wiki/Wikipedia:Manual_of_Style/Linking\n",
      "depth: 1 / 1\t:\thttps://en.wikipedia.org/wiki/Given_name\n",
      "depth: 1 / 1\t:\thttps://en.wikipedia.org/w/index.php?title=Alpman&oldid=925236056\n",
      "depth: 1 / 1\t:\thttps://en.wikipedia.org/wiki/Help:Category\n",
      "depth: 1 / 1\t:\thttps://en.wikipedia.org/wiki/Category:Surnames\n",
      "depth: 1 / 1\t:\thttps://en.wikipedia.org/wiki/Category:Articles_with_short_description\n",
      "depth: 1 / 1\t:\thttps://en.wikipedia.org/wiki/Category:All_set_index_articles\n",
      "depth: 1 / 1\t:\thttps://en.wikipedia.org/wiki/Category:Monitored_short_pages\n",
      "depth: 1 / 1\t:\thttps://en.wikipedia.org/wiki/Special:MyTalk\n",
      "depth: 1 / 1\t:\thttps://en.wikipedia.org/wiki/Special:MyContributions\n",
      "depth: 1 / 1\t:\thttps://en.wikipedia.org/wiki/Alpman/w/index.php?title=Special:CreateAccount&returnto=Alpman\n",
      "Ignored:  HTTP Error 404: Not Found\n",
      "Ignored:  HTTP Error 404: Not Found\n",
      "depth: 1 / 1\t:\thttps://en.wikipedia.org/wiki/Alpman/w/index.php?title=Special:UserLogin&returnto=Alpman\n",
      "Ignored:  HTTP Error 404: Not Found\n",
      "Ignored:  HTTP Error 404: Not Found\n",
      "depth: 1 / 1\t:\thttps://en.wikipedia.org/wiki/Talk:Alpman\n",
      "depth: 1 / 1\t:\thttps://en.wikipedia.org/wiki/Alpman/w/index.php?title=Alpman&action=edit\n",
      "depth: 1 / 1\t:\thttps://en.wikipedia.org/wiki/Alpman/w/index.php?title=Alpman&action=history\n",
      "Ignored:  HTTP Error 404: Not Found\n",
      "Ignored:  HTTP Error 404: Not Found\n",
      "depth: 1 / 1\t:\thttps://en.wikipedia.org/wiki/Main_Page\n",
      "depth: 1 / 1\t:\thttps://en.wikipedia.org/wiki/Wikipedia:Contents\n",
      "depth: 1 / 1\t:\thttps://en.wikipedia.org/wiki/Portal:Featured_content\n",
      "depth: 1 / 1\t:\thttps://en.wikipedia.org/wiki/Portal:Current_events\n",
      "depth: 1 / 1\t:\thttps://en.wikipedia.org/wiki/Special:Random\n",
      "depth: 1 / 1\t:\thttps://donate.wikimedia.org/wiki/Special:FundraiserRedirector?utm_source=donate&utm_medium=sidebar&utm_campaign=C13_en.wikipedia.org&uselang=en\n",
      "depth: 1 / 1\t:\thttps://shop.wikimedia.org\n",
      "depth: 1 / 1\t:\thttps://en.wikipedia.org/wiki/Help:Contents\n",
      "depth: 1 / 1\t:\thttps://en.wikipedia.org/wiki/Wikipedia:About\n",
      "depth: 1 / 1\t:\thttps://en.wikipedia.org/wiki/Wikipedia:Community_portal\n",
      "depth: 1 / 1\t:\thttps://en.wikipedia.org/wiki/Special:RecentChanges\n",
      "depth: 1 / 1\t:\thttps://en.wikipedia.org/wiki/Wikipedia:Contact_us\n",
      "depth: 1 / 1\t:\thttps://en.wikipedia.org/wiki/Special:WhatLinksHere/Alpman\n",
      "depth: 1 / 1\t:\thttps://en.wikipedia.org/wiki/Special:RecentChangesLinked/Alpman\n",
      "depth: 1 / 1\t:\thttps://en.wikipedia.org/wiki/Wikipedia:File_Upload_Wizard\n",
      "depth: 1 / 1\t:\thttps://en.wikipedia.org/wiki/Special:SpecialPages\n",
      "depth: 1 / 1\t:\thttps://en.wikipedia.org/wiki/Alpman/w/index.php?title=Alpman&oldid=925236056\n",
      "depth: 1 / 1\t:\thttps://en.wikipedia.org/wiki/Alpman/w/index.php?title=Alpman&action=info\n",
      "depth: 1 / 1\t:\thttps://www.wikidata.org/wiki/Special:EntityPage/Q56537475\n",
      "depth: 1 / 1\t:\thttps://en.wikipedia.org/wiki/Alpman/w/index.php?title=Special:CiteThisPage&page=Alpman&id=925236056\n",
      "Ignored:  HTTP Error 404: Not Found\n",
      "Ignored:  HTTP Error 404: Not Found\n",
      "depth: 1 / 1\t:\thttps://en.wikipedia.org/wiki/Alpman/w/index.php?title=Special:Book&bookcmd=book_creator&referer=Alpman\n",
      "Ignored:  HTTP Error 404: Not Found\n",
      "Ignored:  HTTP Error 404: Not Found\n",
      "depth: 1 / 1\t:\thttps://en.wikipedia.org/wiki/Alpman/w/index.php?title=Special:ElectronPdf&page=Alpman&action=show-download-screen\n",
      "Ignored:  HTTP Error 404: Not Found\n",
      "Ignored:  HTTP Error 404: Not Found\n",
      "depth: 1 / 1\t:\thttps://en.wikipedia.org/wiki/Alpman/w/index.php?title=Alpman&printable=yes\n",
      "Ignored:  HTTP Error 404: Not Found\n",
      "Ignored:  HTTP Error 404: Not Found\n",
      "depth: 1 / 1\t:\thttps://www.wikidata.org/wiki/Special:EntityPage/Q56537475#sitelinks-wikipedia\n",
      "depth: 1 / 1\t:\thttps://en.wikipedia.org/wiki/Wikipedia:Text_of_Creative_Commons_Attribution-ShareAlike_3.0_Unported_License\n",
      "depth: 1 / 1\t:\thttps://creativecommons.org/licenses/by-sa/3.0/\n",
      "Ignored:  HTTP Error 403: Forbidden\n",
      "Ignored:  HTTP Error 403: Forbidden\n",
      "depth: 1 / 1\t:\thttps://foundation.wikimedia.org/wiki/Terms_of_Use\n",
      "depth: 1 / 1\t:\thttps://foundation.wikimedia.org/wiki/Privacy_policy\n",
      "depth: 1 / 1\t:\thttps://www.wikimediafoundation.org/\n",
      "depth: 1 / 1\t:\thttps://en.wikipedia.org/wiki/Wikipedia:General_disclaimer\n",
      "depth: 1 / 1\t:\thttps://www.mediawiki.org/wiki/Special:MyLanguage/How_to_contribute\n",
      "depth: 1 / 1\t:\thttps://stats.wikimedia.org/v2/#/en.wikipedia.org\n",
      "depth: 1 / 1\t:\thttps://foundation.wikimedia.org/wiki/Cookie_statement\n",
      "depth: 1 / 1\t:\thttps://en.m.wikipedia.org/w/index.php?title=Alpman&mobileaction=toggle_view_mobile\n",
      "depth: 1 / 1\t:\thttps://wikimediafoundation.org/\n",
      "depth: 1 / 1\t:\thttps://www.mediawiki.org/\n",
      "CPU times: user 10.2 s, sys: 421 ms, total: 10.6 s\n",
      "Wall time: 1min 46s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "# url = 'https://pl.wikipedia.org/wiki/Specjalna:Losowa_strona'\n",
    "url = 'https://en.wikipedia.org/wiki/Alpman'\n",
    "bfs = BFS(url, 0, 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "metadata": {},
   "outputs": [],
   "source": [
    "def most_occurances(bfs):\n",
    "    word_occ_counts = {}\n",
    "    for k, v in bfs.items():\n",
    "        word_occ_counts[k] = sum(list(map(lambda kv : kv[1], v)))\n",
    "    word_occ_counts = sort_dict(word_occ_counts)\n",
    "    woc = next(iter(word_occ_counts.items()))\n",
    "    return woc\n",
    "\n",
    "def most_websites_for_word(bfs):\n",
    "    word_web_counts = {}\n",
    "    for k, v in bfs.items():\n",
    "        word_web_counts[k] = len(v)\n",
    "    word_web_counts = sort_dict(word_web_counts)\n",
    "    wwc = next(iter(word_web_counts.items()))\n",
    "    return wwc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 172,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The most occurances had the word 'the': 4028\n",
      "The word 'from' appeared on most websites: 50\n"
     ]
    }
   ],
   "source": [
    "woc = most_occurances(bfs)\n",
    "wwc = most_websites_for_word(bfs)\n",
    "print(f'The most occurances had the word \\'{woc[0]}\\': {woc[1]}')\n",
    "print(f'The word \\'{wwc[0]}\\' appeared on most websites: {wwc[1]}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Multiprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 145,
   "metadata": {},
   "outputs": [],
   "source": [
    "def BFS_concurrent(url, max_depth):\n",
    "    visited = {url}\n",
    "\n",
    "    all_websites = [url]\n",
    "    cur_websites = [url]\n",
    "    \n",
    "    # get all hrefs for every website\n",
    "    for _ in range(max_depth):\n",
    "        with concurrent.futures.ThreadPoolExecutor() as executor:\n",
    "            cur_websites = list(executor.map(find_hrefs, cur_websites))[0]\n",
    "        all_websites += cur_websites\n",
    "    all_websites = list(set(all_websites))\n",
    "        \n",
    "    # find words for every website\n",
    "    with concurrent.futures.ThreadPoolExecutor() as executor:\n",
    "        list_d = list(executor.map(count_words, all_websites))  # list of dicts - word: (website, #occurances)\n",
    "    \n",
    "    website_word_counts = defaultdict(list)\n",
    "    for d in list_d:\n",
    "        with concurrent.futures.ThreadPoolExecutor() as executor:\n",
    "            executor.map(lambda kv: website_word_counts[kv[0]].append(kv[1]), d.items())\n",
    "        \n",
    "    # sort websites by no of appereances for every word\n",
    "    for k, v in website_word_counts.items():\n",
    "        website_word_counts[k] = list(sorted(website_word_counts[k], key=lambda kv: kv[1], reverse=True))\n",
    "    \n",
    "    return website_word_counts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 146,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ignored:  HTTP Error 404: Not Found\n",
      "Ignored:  HTTP Error 404: Not Found\n",
      "Ignored:  HTTP Error 403: Forbidden\n",
      "Ignored:  HTTP Error 404: Not Found\n",
      "Ignored:  HTTP Error 404: Not Found\n",
      "Ignored:  HTTP Error 404: Not Found\n",
      "Ignored:  HTTP Error 404: Not Found\n",
      "Ignored:  HTTP Error 404: Not Found\n",
      "59\n",
      "CPU times: user 5.18 s, sys: 249 ms, total: 5.43 s\n",
      "Wall time: 6.34 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "bfs_concurrent = BFS_concurrent(url, 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The most occurances had the word 'the': 4013\n",
      "The word 'from' appeared on most websites: 50\n"
     ]
    }
   ],
   "source": [
    "woc = most_occurances(bfs_concurrent)\n",
    "wwc = most_websites_for_word(bfs_concurrent)\n",
    "\n",
    "print(f'The most occurances had the word \\'{woc[0]}\\': {woc[1]}')\n",
    "print(f'The word \\'{wwc[0]}\\' appeared on most websites: {wwc[1]}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
